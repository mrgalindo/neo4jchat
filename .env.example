# Neo4j Connection
NEO4J_URI=neo4j+s://your-instance.databases.neo4j.io
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your-password
NEO4J_DATABASE=neo4j

# OpenAI
OPENAI_API_KEY=sk-your-api-key
# Optional custom base URL for OpenAI-compatible endpoints
# OPENAI_BASE_URL=https://api.openai.com/v1

# Anthropic (optional)
# ANTHROPIC_API_KEY=sk-ant-...

# Groq (optional)
# GROQ_API_KEY=groq-...

# Google Generative AI (optional)
# GOOGLE_API_KEY=AIza...

# Choose default provider when model has no prefix: openai|anthropic|groq|google
LLM_PROVIDER=openai

# Default LLM used for Cypher generation
CYPHER_LLM_MODEL=openai/gpt-4
# LLM used for QA summarization and semantic RetrievalQA (defaults to CYPHER_LLM_MODEL if unset)
QA_LLM_MODEL=openai/gpt-4


# Agent model used by the LangGraph agent (CLI --model overrides)
AGENT_LLM_MODEL=openai/gpt-4o

# Application
LOG_LEVEL=INFO
CACHE_ENABLED=true
EMBEDDING_MODEL=text-embedding-ada-002
EMBEDDING_DIMENSIONS=1536
BATCH_SIZE=100

# Phoenix tracing (self-hosted)
PHOENIX_OTLP_ENDPOINT=http://localhost:6006/v1/traces
SERVICE_NAME=neo4jchat-langgraph

# Phoenix Cloud (set these when using Phoenix Cloud)
# Copy Hostname from your Phoenix Cloud Space settings (no /v1/traces needed)
PHOENIX_COLLECTOR_ENDPOINT=https://your-phoenix-hostname
# Create an API key in the Phoenix Cloud Space settings
PHOENIX_API_KEY=your-phoenix-api-key
# For Phoenix Cloud instances created before June 24, 2025, add the API key as a header:
# PHOENIX_CLIENT_HEADERS=api_key=${PHOENIX_API_KEY}
# Optional: project name shown in Phoenix (defaults to SERVICE_NAME)
PHOENIX_PROJECT_NAME=neo4jchat-langgraph

# LLM temperature controls
# If unset or set to 'null', temperature is not sent to the model.
# For OpenAI reasoning models (o1/o3/o4*), temperature is automatically omitted even if set.
DEFAULT_TEMPERATURE=0
AGENT_TEMPERATURE=0
CYPHER_TEMPERATURE=0
QA_TEMPERATURE=0

# Semantic Search Configuration
# Number of documents to retrieve from vector index (1-50)
SEMANTIC_SEARCH_K=5
# Minimum similarity score threshold for filtering results (0.0-1.0, 0.0 = no filtering)
SEMANTIC_SEARCH_SIMILARITY_THRESHOLD=0.0
# Enable reranking for improved semantic relevance (true/false)
SEMANTIC_SEARCH_USE_RERANKER=false
# Reranker type: none, cohere
SEMANTIC_SEARCH_RERANKER_TYPE=none
# Number of final results after reranking (must be <= SEMANTIC_SEARCH_K)
SEMANTIC_SEARCH_RERANKER_TOP_K=3

# Cohere Reranker (optional - required only if using cohere reranker)
# COHERE_API_KEY=your-cohere-api-key
# COHERE_RERANK_MODEL=rerank-english-v3.0

# -----------------------------
# Agent & Tool Prompts (customization)
# -----------------------------
# Recommended: file-based prompts. Use defaults under prompts/ as starting points.
AGENT_SYSTEM_PROMPT_FILE=prompts/agent_system_prompt_default.txt
# AGENT_SYSTEM_PROMPT=

# Semantic QA (RetrievalQA "stuff"); required variables: {context}, {question}
SEMANTIC_QA_PROMPT_FILE=prompts/semantic_qa_default.txt
# SEMANTIC_QA_PROMPT=

# Cypher generation (GraphCypher); required variables: {schema}, {question}
CYPHER_GENERATION_PROMPT_FILE=prompts/cypher_generation_default.txt
# CYPHER_GENERATION_PROMPT=

# Graph QA (GraphCypher); required variables: {context}, {question}
GRAPH_QA_PROMPT_FILE=prompts/graph_qa_default.txt
# GRAPH_QA_PROMPT=

# Hybrid synthesis (optional final LLM step); required variables: {content_insights}, {structural_relationships}, {question}
HYBRID_SYNTHESIS_PROMPT_FILE=prompts/hybrid_synthesis_default.txt
# HYBRID_SYNTHESIS_PROMPT=

# Optional: custom OpenAI-compatible base URLs
# OPENAI_BASE_URL=
# LLM_OPENAI_BASE_URL=
